{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rtudsww/transportation-project/blob/main/human%20detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "\n",
        "\n",
        "!pip install ultralytics\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import detectron2\n",
        "\n",
        "\n",
        "\n",
        "!pip install supervision==0.2.0\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import supervision as sv"
      ],
      "metadata": {
        "id": "tsHUlFiSMwhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "NaqiKryiMpLb",
        "outputId": "1758e42d-020d-454a-ab54-e6c87269f8de"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ultralytics'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-68bca18fca99>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"/content/WhatsApp Video 2024-02-11 at 12.14.14_8f8e9682.mp4.mp4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yolov8s.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# v1=f\"/content/v1.mp4\"\n",
        "# v2=f\"/content/v2.mp4\"\n",
        "v1=f\"/content/WhatsApp Video 2024-02-11 at 12.14.14_8f8e9682.mp4.mp4\"\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8s.pt')\n",
        "\n",
        "\n",
        "\n",
        "# for single frame--\n",
        "# generator = sv.get_video_frames_generator(v1)\n",
        "# iterator = iter(generator)\n",
        "# frame = next(iterator)\n",
        "\n",
        "# # detect\n",
        "# results = model(frame, imgsz=1280)[0]\n",
        "# detections = sv.Detections.from_yolov8(results)\n",
        "\n",
        "# # annotate\n",
        "# box_annotator = sv.BoxAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
        "# frame = box_annotator.annotate(scene=frame, detections=detections)\n",
        "\n",
        "# %matplotlib inline\n",
        "# sv.show_frame_in_notebook(frame, (16, 16))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## for 10 frames::\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "generator = sv.get_video_frames_generator(v1)\n",
        "\n",
        "\n",
        "box_annotator = sv.BoxAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
        "\n",
        "\n",
        "max_frames = 10\n",
        "\n",
        "\n",
        "for frame_number, frame in tqdm(enumerate(generator), desc=\"Processing frames\", total=max_frames):\n",
        "\n",
        "    results = model(frame, imgsz=1280)[0]\n",
        "    detections = sv.Detections.from_yolov8(results)\n",
        "\n",
        "\n",
        "    frame = box_annotator.annotate(scene=frame, detections=detections)\n",
        "\n",
        "\n",
        "    sv.show_frame_in_notebook(frame, (16, 16))\n",
        "\n",
        "    if frame_number + 1 == max_frames:\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "### on running vid detection::\n",
        "# import cv2\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# # Assuming v1 is your video file\n",
        "# generator = sv.get_video_frames_generator(v1)\n",
        "\n",
        "# box_annotator = sv.BoxAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
        "\n",
        "# for frame_number, frame in tqdm(enumerate(generator), desc=\"Processing frames\", total=float('inf')):\n",
        "#     results = model(frame, imgsz=1280)[0]\n",
        "#     detections = sv.Detections.from_yolov8(results)\n",
        "\n",
        "#     frame = box_annotator.annotate(scene=frame, detections=detections)\n",
        "\n",
        "#     sv.show_frame_in_notebook(frame, (16, 16))\n",
        "\n",
        "#     # Check for the \"q\" key press to break out of the loop\n",
        "#     key = cv2.waitKey(1) & 0xFF\n",
        "#     if key == ord('q'):\n",
        "#         break\n",
        "\n",
        "# cv2.destroyAllWindows()\n",
        "# Close any remaining OpenCV windows\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# from tqdm import tqdm\n",
        "# import numpy as np\n",
        "# from ultralytics import YOLO\n",
        "\n",
        "# # Assuming v1 is your video file\n",
        "# v1 = \"/content/v1.mp4\"\n",
        "# output_video_path = \"/content/output_video_v1.mp4\"\n",
        "\n",
        "# # Initialize YOLO model\n",
        "# model = YOLO('yolov8s.pt')\n",
        "\n",
        "# # Get video properties\n",
        "# cap = cv2.VideoCapture(v1)\n",
        "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "# width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "# height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# # Define codec and create VideoWriter object\n",
        "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "# out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "# # Initialize BoxAnnotator outside the loop for efficiency\n",
        "# box_annotator = sv.BoxAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
        "\n",
        "# # Loop through all frames in the video\n",
        "# for frame_number, frame in tqdm(enumerate(sv.get_video_frames_generator(v1)), desc=\"Processing frames\"):\n",
        "#     results = model(frame, imgsz=1280)[0]\n",
        "#     detections = sv.Detections.from_yolov8(results)\n",
        "\n",
        "#     # Annotate\n",
        "#     frame = box_annotator.annotate(scene=frame, detections=detections)\n",
        "\n",
        "#     # Save the annotated frame to the output video\n",
        "#     out.write(frame)\n",
        "\n",
        "#     # Display or save the annotated frame as needed\n",
        "\n",
        "#     sv.show_frame_in_notebook(frame, (16, 16))\n",
        "\n",
        "#     if frame_number + 1 == max_frames:\n",
        "#          break\n",
        "\n",
        "# # Release the VideoWriter object\n",
        "# out.release()\n",
        "\n",
        "# # Display the saved video\n",
        "# from IPython.display import Video\n",
        "# Video(output_video_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Assuming v1 is your video file\n",
        "v1 = \"/content/WhatsApp Video 2024-02-11 at 12.14.14_8f8e9682.mp4\"\n",
        "output_video_path = \"/content/output_video_v1.mp4\"\n",
        "\n",
        "# Initialize YOLO model\n",
        "model = YOLO('yolov8s.pt')\n",
        "\n",
        "# Get video properties\n",
        "cap = cv2.VideoCapture(v1)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Define codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "# Initialize BoxAnnotator outside the loop for efficiency\n",
        "box_annotator = sv.BoxAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
        "\n",
        "# Loop through all frames in the video\n",
        "for frame_number in tqdm(range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))), desc=\"Processing frames\"):\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    results = model(frame, imgsz=1280)[0]\n",
        "    detections = sv.Detections.from_yolov8(results)\n",
        "\n",
        "    # Annotate\n",
        "    frame = box_annotator.annotate(scene=frame, detections=detections)\n",
        "\n",
        "    # Save the annotated frame to the output video\n",
        "    out.write(frame)\n",
        "\n",
        "    # Display or save the annotated frame as needed\n",
        "    sv.show_frame_in_notebook(frame, (16, 16))\n",
        "\n",
        "# Release the VideoWriter object\n",
        "out.release()\n",
        "\n",
        "# Display the saved video\n",
        "from IPython.display import Video\n",
        "Video(output_video_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "vDBqT9WCNGMK",
        "outputId": "fbae49cd-44fe-4264-ed7b-fd6c65acb291"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ultralytics'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3a952b53842b>\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# Assuming v1 is your video file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}